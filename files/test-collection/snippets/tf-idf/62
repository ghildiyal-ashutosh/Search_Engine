Snippets for the query:  Q62
************************
Total Hits:  57
************************

************************
Document:  CACM-3151.html
************************


an optimal real-time algorithm for planar convex hulls

an algorithm is described for the construction in real-time of the
convex hull of a set of n points in the plane.   using an appropriate data
structure, the algorithm constructs the convex hull by successive
updates, each taking time o(log n), thereby achieving a total
processing time o(n log n).  

cacm july, 1979

preparata, f.

computational geometry, convex hull, planar set of
points, real-time algorithms, on-line algorithms. 
************************

************************
Document:  CACM-2135.html
************************


rapid computation of general interpolation
formulas and mechanical quadrature rules

let f have n continuous on a closed interval
[a,b] and let l be a linear functional.  the attempt 
is made to approximate l (f) with l (q) where q is a polynomial,
approximating f.  algorithms are developed 
for rapid 
************************

************************
Document:  CACM-2884.html
************************


permutation enumeration: four new permutation algorithms

classical permutation enumeration algorithms encounter
special cases requiring additional computation 
every nth permutation 
************************
 
every nth permutation when generating the n! permutations
on n marks.  four new algorithms have the attribute 
that special cases occur every n(n-1)permutations. 
two of the algorithms produce the next permutation 
with a single exchange of two marks.  the other two algorithms
infrequently exchange more than two marks, 
but the rules for generating the next permutation are
very simple.  performance tests which have counted 
execution of assignment statements, comparisons, arithmetic
operations, 
************************

************************
Document:  CACM-2692.html
************************


reentrant polygon clipping

a new family of clipping algorithms is described.
 these algorithms are able to clip polygons 
against irregular convex plane-faced volumes in three
dimensions, removing the parts of the polygon which 
lie outside the volume.  in two dimensions the algorithms
permit clipping against irregular convex windows. 
 polygons to be clipped are represented as an ordered
sequence of vertices without repetition of first 
and last, in marked contrast to representation as a
collection of edges as was heretofore the common 
procedure.  output polygons have an identical format,
with new vertices introduced in sequence to describe 
any newly-cut edge or edges.  the algorithms easily handle
the particularly difficult problem of detecting 
that a new vertex may be required at a corner of the
clipping window.  the algorithms described achieve 
considerable simplicity by clipping separately against
each clipping plane or window boundary.  code 
capable of clipping the polygon against a single boundary
is reentered to clip against subsequent boundaries. 
 each such reentrant stage of clipping need store only
two vertex values and may begin its processing 
as soon as the first output vertex from the proceeding
stage is ready.  because the same code is reentered 
for clipping against subsequent boundaries, clipping
against very complex window shapes is practical. 
 for perspective applications in three dimentions, a six-plane
truncated pyramid is chosen as the clipping 
volume.  the two additional planes parallel to the projection
screen serve to limit the range of depth 
preserved through the projection.  a perspective projection
method which provides for arbitrary view 
angles and depth of field in spite of simple fixed clipping
planes is described.  this method is ideal 
for subsequent hidden-surface computations.

cacm january, 1974

************************

************************
Document:  CACM-3059.html
************************


models for parallel processing within programs:
application to cpu:i/o and i/o:i/o overlap

approximate queueing models for internal parallel
processing by individual programs in a multiprogrammed 
system are developed in this paper.  the solution technique
is developed by network decomposition.  the 
models are formulated in terms of cpu:i/o and i/o:i/o overlap
and applied to the analysis of these problems. 
 the percentage performance improvement from cpu:i/o
overlap is found to be greatest for systems which 
are in approximate cpu:i/o utilization balance and for
low degrees of multiprogramming.  the percentage 
improvement from i/o:i/o overlap is found to be greatest
for systemtems in which the i/o system is more 
utilized than the cpu.

cacm october, 1978

towsley, d.
chandy, k.
browne, j.

multiprogramming, parallel processing, queueing
network models, multiprocessing of computation 
and i/o 

4.32 8.1

************************

************************
Document:  CACM-1953.html
************************
************************
Document:  CACM-2062.html
************************
************************
Document:  CACM-1796.html
************************
************************
Document:  CACM-2997.html
************************


convex hulls of finite sets of poin ts in two and three dimensions

the convex hulls of sets of n poin ts in two
and three dimensions can be determined with o(n 
log n) operations.  the presented algorithms use the "divide
and conquer" technique and recursively apply 
a merge procedure for two nonin tersecting convex hulls.
 since any convex hull algorithm requires at 
least o(n log n) operations, the time complexity of the
proposed algorithms is optimal within a multiplicative 
constant.

cacm february, 1977

preparata, f. p.
hong, s. j.

computational complexity, convex 
************************

************************
Document:  CACM-1171.html
************************
************************
Document:  CACM-2283.html
************************
************************
Document:  CACM-2146.html
************************
************************
Document:  CACM-3156.html
************************


computing connected components on parallel computers

we present a parallel algorithm which uses n2 processors to find the connected
components of an undirected graph with n vertices in time o(log2n).  an
o(log2n) time bound also can be achieved using only n$n/$log2n)) processors.
the algorithm can be used to find the transitive closure
of a symmetric boolean matrix.  we assume that the processors have
access to a common memory.  simultaneous access to the same location
is permitted for fetch instructions but not for store instructions.

cacm august, 1979

hirschberg, d.
chandra, a.
sarwate, d.

graph theory, parallel processing, algorithms,
transitive closure, 
************************

************************
Document:  CACM-2266.html
************************


a highly parallel algorithm for approximating
all zeros of a polynomial with only real zeros

an algorithm is described based on newton's
method which simultaneously approximates all zeros 
of a polynomial with only real zeros.  the algorithm, which
is conceptually suitable for parallel computation, 
determines its own 
************************
, 
determines its own starting values so that convergence
to the zeros is guaranteed.  multiple zeros and 
their multiplicity are readily determined.  at no
point in the method is polynomial deflation used.

cacm november, 1972

patrick, m. l.

parallel numerical algorithms, real polynomials,
real 
************************

************************
Document:  CACM-2896.html
************************


an exercise in proving parallel programs correct

a parallel program, dijkstra's on-the-fly garbage
collector, is proved correct using a proof 
method developed by owicki.  the fine degree of in terleaving
in this program makes it especially difficult 
to understand, 
************************

************************
Document:  CACM-2342.html
************************
************************
Document:  CACM-1302.html
************************
************************
Document:  CACM-1658.html
************************


analysis of algorithms for the zero-one programming problem

this paper is concerned with a review and examination
of several existing algorithms for the 
zero-one programming problem.  computational experience
is summarized. 
************************

************************
Document:  CACM-2306.html
************************


ancient babylonian algorithms

the early origins of mathematics are discussed,
emphasizing those aspects which seem to be 
of greatest interest from the standpoint of computer
science.  a number of old babylonian tablets, many 
of which have never before been translated into english, are quoted.

cacm july, 1972

knuth, d. e.

history of computation, babylonian tablets,

************************

************************
Document:  CACM-0371.html
************************
************************
Document:  CACM-2627.html
************************
************************
Document:  CACM-2557.html
************************


on the time required for a sequence of matrix products

this paper discusses the multiplication of conformable
sequences of row vectors, column vectors, 
and square matrices.  the minimum time required to evaluate
such products on ordinary serial computers 
as well as parallel computers is discussed.  algorithms
are presented which 
************************

************************
Document:  CACM-2700.html
************************


reduction: a method of proving properties of parallel programs

when proving that a parallel program has a
given property it is often convenient to assume 
that a statement is indivisible, i.e. that the statement
cannot be interleaved with the rest of the program. 
 here sufficient conditions are obtained to show that
the assumption that a statement is indivisible 
can be relaxed and still preserve properties such as
halting.  thus correctness proofs of a parallel 
system can often be greatly simplified.

cacm december, 1975

lipton, r. j.

deadlock free, reduction, interruptible, indivisible,
parallel program, semaphore, verification 
method, process, computation sequence

4.32 4.35 
************************

************************
Document:  CACM-2767.html
************************


a comparison of simulation event list algorithms

four algorithms are considered which can be used
to schedule events in a general purpose discrete 
simulation system.  two of the algorithms are new, one
is based on an end-order tree structure for event 
notices, and another uses an indexed linear list. the algorithms
are tested with a set of typical stochastic 
scheduling distributions especially chosen to show
the advantages 
************************

************************
Document:  CACM-2337.html
************************


a sorting problem and its complexity

a technique for proving min-max norms of sorting
algorithms is given.  one new algorithm for 
finding the minimum and maximum elements of a set with
fewest comparisons is proved optimal with this 
technique.

cacm june, 1972

pohl, i.

sorting, computational complexity, computational 
************************

************************
Document:  CACM-0320.html
************************


logic-structure tables

logic tables are an excellent way of developing
and expressing the logic required in procedures, 
operations, systems and circuits.  a set of rules for
writing and using logic tables is explained by 
means of some simple examples.  then the logic structure
of a vending machine is given in which two logic 
tables are used.  logic tables are two-dimensional in
nature, enabling us to fully express and consider 
both the sequential and parallel aspects of logic.  they

************************

************************
Document:  CACM-3075.html
************************


fast parallel sorting algorithms

a parallel bucket-sort 
************************


a parallel bucket-sort algorithm is presented
that requires time o(log n) and the use of n 
processors.  the algorithm makes use of a technique that
requires more space than the product of processors 
and time.  a realistic model is used model is used in which
no memory contention is permitted.  a procedure 
is also presented to sort n numbers in time o(k log
n) using n 1 + 1/k processors, for k an arbitrary 
integer.  the model of computation for this procedure
permits simultaneous fetches from the same memory 
location.

cacm august, 1978

hirschberg, d.

parallel processing, sorting, algorithms, bucket sort

3.74 4.34 
************************

************************
Document:  CACM-2175.html
************************


subexpression ordering in the execution of arithmetic expressions

an arithmetic expression can often be broken
down into its component subexpressions.  depending 
on the hardware environment in which the expression is
to be executed, these subexpressions can be evaluated 
in serials, in parallel, or in a combination of these
modes.  this paper shows that expression execution 
time can be minimized only if consideration is given to
the ordering of the subexpressions.  in particular, 
subexpressions should be executed in order of decreasing
memory and processor time requirements.  this 
observation is valid for configurations ranging from
a uniprocessor with an unbuffered main memory to 
multiprocessor with a "cache" buffer memory.  if the
number of subexpressions which can be executed in 
parallel exceeds the number of available processors,
then execution of some of these subexpressions must 
be postponed.  a procedure is given which combines this
requirement with the earlier ordering considerations 
to provide an optimal execution sequence.

cacm july, 1971

ramamoorthy, c. v.
gonzalez, m. j.

parallel processing, cache, arithmetic expressions,
subexpression ordering, computational trees, 
compilers

************************

************************
Document:  CACM-2433.html
************************


control structures in illiac iv fortran

as part of an effort to design and implement
a fortran compiler on the illiac iv, an extended 
fortran, called ivtran, has been developed.  this language
provides a means of expressing data and control 
structures suitable for exploiting illiac iv parallelism.
 this paper reviews the hardware characteristics 
of the illiac and singles out unconventional features
which could be expected to influence language (and 
compiler) design.  the implications of these features for
data layout and algorithm structure are discussed, 
and the conclusion is drawn that data allocation rather than
code structuring is the crucial illiac optimization 
problem.  a satisfactory method of data allocation is
then presented.  language structures to utilize 
this storage method and express parallel algorithms are described.

cacm 
************************

************************
Document:  CACM-2226.html
************************


further evidence for the analysis of algorithms
for the zero-one programming problem

the purpose of this note is to report computational
experience additional 
************************

************************
Document:  CACM-1411.html
************************


comparison of several algorithms for computation
of means, standard deviations 
************************

of means, standard deviations and correlation 
coefficients

several algorithms for computation of basic
statistics 
************************

************************
Document:  CACM-0676.html
************************
************************
Document:  CACM-1811.html
************************


a case study in programming for parallel-processors

an affirmative partial answer is provided to
the question of whether it is possible to program 
parallel-processor computing systems to efficiently decrease
execution time for useful problems.  parallel-processor 
systems are multiprocessor systems in which several of
the processors can simultaneously execute separate 
tasks of a single job, thus cooperating to decrease
the solution time of a computational problem. the 
processors 
************************

************************
Document:  CACM-2630.html
************************
************************
Document:  CACM-0950.html
************************


parallel methods for integrating ordinary differential equations

this paper is dedicated to the proposition that,
in order to take full advantage for real-time 
computations of highly parallel 
************************
s of highly parallel computers as can be
expected to be available in the near future, much 
of numerical analysis will have to be recast in a more
"parallel" form.  by this is meant that serial 
algorithms ought to be replaced 
************************

************************
Document:  CACM-2895.html
************************


a language for formal problem specification

a language for specifying the in tended behavior
of communicating parallel processes is described. 
 the specifications are constrain ts on the order in which
events of a computation can occur.  the language 
************************

************************
Document:  CACM-2263.html
************************


the conversion of limited-entry decision tables
to optimal and near-optimal flowcharts: two new 
algorithms

two new algorithms for deriving optimal and
near-optimal flowcharts from limited entry decision 
tables are presented.  both take into account rule frequencies
and the time needed to test conditions. 
 one of the algorithms, called the optimum-finding algorithm,
leads to a flowchart which truly minimizes 
execution time for a decision table in which simple rules
are already contracted to complex rules.  the 
other one, called the optimum-approaching algorithm, requires
many fewer calculations but does not necessarily 
produce the optimum flowchart.  the algorithms are first
derived for treating decision tables not containing 
an else-rule, but the optimum-approaching algorithm
is shown to be equally valid for tables including 
such a rule.  both algorithms are compared with existing
ones and are applied to a somewhat large decision 
table derived from a real case.  from this comparison two
conclusions are drawn.  (1) the optimum-approaching 
algorithm will usually lead to better results than comparable
existing ones and will not require more, 
but usually less, computation time.(2) in general, 
************************

************************
Document:  CACM-1660.html
************************
************************
Document:  CACM-2685.html
************************
************************
Document:  CACM-1873.html
************************
************************
Document:  CACM-1601.html
************************


parallel numerical methods for the solution of equations

classical iterative procedures for the numerical
solution of equations provide at each stage 
a single new approximation to the root in question.  a
technique is given for the development of numerical 
procedures which provide, at each stage, several approximations
to a solution of an equation.  the s8everal 
approximations obtained in any iteration are computationally
independent, making the methods of interest 
in a parallel processing environment.  convergence is
insured by extracting the "best information" at 
each iteration.  several families of numerical procedures
which use the technique of the procedures in 
a parallel processing environment are developed and measurements
of these statistics are reported.  these 
measurements are interpreted in a parallel processing
environment.  in such an environment the procedures 
obtained are superior to standard algorithms.

cacm may, 1967

shedler, 
************************

************************
Document:  CACM-1644.html
************************
************************
Document:  CACM-1851.html
************************
************************
Document:  CACM-3058.html
************************
************************
Document:  CACM-2973.html
************************


sorting on a mesh-connected parallel computer

two algorithms are presented for sorting 
************************
 are presented for sorting n^2
elements on an n x n mesh-connected processor 
array that require o(n) routing and comparison steps.
 the best previous algorithm takes time o(n log 
n).  the algorithms of this paper are shown to be optimal
in time within small constant factors.  extensions 
to higher-dimensional arrays are also given.

cacm april, 1977

thompson, c. d.
kung, h. t.

parallel computer, parallel sorting, 
************************

************************
Document:  CACM-2325.html
************************


numerical mathematics and computer science

numerical mathematics is viewed as the analysis
of continuous algorithms.  four of the components 
of numerical mathematics are discussed.  these are: foundations
(finite precision number systems, computational 
complexity), synthesis 
************************
al 
complexity), synthesis and analysis of algorithms,
analysis of error, programs and program libraries.

cacm july, 1972

traub, j. f.

numerical mathematics, computer science, mathematics
of computation, algorithms, continuous 
************************

************************
Document:  CACM-2426.html
************************
************************
Document:  CACM-1952.html
************************
************************
Document:  CACM-2950.html
************************
************************
Document:  CACM-2267.html
************************
************************
Document:  CACM-1795.html
************************


optimal code for serial and parallel computation

cacm december, 1969

************************

************************
Document:  CACM-2570.html
************************


a comparison of list schedules for parallel processing systems

the problem of scheduling two or more processors
to minimize the execution time of a program 
which consists of a set of partially ordered tasks
is studied.  cases where task execution times are 
deterministic and others in which execution times are
random variables are analyzed.  it is shown that 
different algorithms suggested in the literature 
************************

************************
Document:  CACM-2195.html
************************
************************
Document:  CACM-0804.html
************************
************************
Document:  CACM-2312.html
************************
************************
Document:  CACM-0270.html
************************
************************
Document:  CACM-2903.html
************************


improving programs by the introduction of recursion

a new technique of program transformation,
called "recursion in troduction," is described and 
applied to two algorithms which solve pattern matching problems.
 by using recursion in troduction, algorithms 
which manipulate a stack are first translated into
recursive algorithms in which no stack operations 
occur.  these algorithms are then subjected to a second
transformation, a method of recursion elimination 
called "tabulation," to produce programs with a very
efficient running time.  in particular, it is shown 
how the fast linear pattern matching algorithm of knuth,
morris, and pratt can be derived in a few steps 
from a simple nonlinear stack algorithm.

cacm november, 1977

bird, r. s.

program transformation, optimization of programs,
recursion elimination, pattern matching algorithms, 
stacks, computational induction

4.0 4.2 
************************

************************
Document:  CACM-1846.html
************************


on simulating networks of parallel processes
in which simultaneous events may occur

some of the problems of simulating discrete
event systems, particularly computer systems, on 
a conventional digital computer are dealt with.  the
systems are assumed to be described as a network 
of interconnected sequential processes.  briefly reviewed
are the common techniques used to handle such 
simulations when simultaneous events do not occur, can
be ignored, or can be handled by simple priority 
rules.  following this, the problem of dealing with simultaneous
events in separate processes is introduced. 
 an abstraction of this problem is developed which admits
solution for a majority of commonly encountered
problems.  the technique will either find a method of
simulating the parallel events or report that none 
can be found.  in some of the latter cases it is shown
to be possible to find a solution by extending 
the information available to the solution technique, but
in many cases the technique becomes computationally 
unfeasible when 
************************

************************
Document:  CACM-3132.html
************************
************************
Document:  CACM-2851.html
************************


formal verification of parallel programs

two formal models for parallel computation
are presented: an abstract 
************************

************************
Document:  CACM-2904.html
************************
************************
Document:  CACM-2007.html
************************
************************
Document:  CACM-2324.html
************************


management science: a view from nonlinear programming

a brief history of integer and continuous
nonlinear programming is presented as well as the 
current obstacles to practical use of these mathematical
programming techniques.  it is forecast that 
the useful contributions to nonlinear programming actually
made in the next few years are more likely 
to be consolidations than theoretical breakthroughs.  these
contributions are likely to be the documentation 
of standard test problems, construction of user oriented
software, and comparisons of currently known 
algorithms to demonstrate which 
************************

************************
Document:  CACM-2114.html
************************


a formal system for information retrieval from files

a generalized file structure is provided
by which the concepts of keyword, index, record, file, directory,
file structure, directory decoding, and record retrieval are defined
and from which some of the frequently used file structures such
as inverted files, index-sequential files, and multilist files are
derived.  two algorithms which retrieve records 
************************
 which retrieve records from the generalized file 
structure are presented.

cacm february, 1970

hsiao, d.

attribute-value pair, index, keyword, record, record address,
k-pointer, k-list, file, directory, generalized file
structure, inverted file, index-sequential-file, multilist file,
description, file search, directory search, serial processing of
lists, prime keyword, parallel processing of lists 
************************

************************
Document:  CACM-2953.html
************************


notes on recursion elimination

various methods of recursion elimination are
applied to the schematic recursive procedure: 
proc s(x); px then n(x); s(fx); s(gx); m(x) fi.  procedures
with this general form arise in connection 
with tree traversal and sorting algorithms.  each method
of recursion removal involves the use of one 
or more stacks, and the solutions are compared
on the basis of their running time.

cacm june, 1977

bird, r. s.

recursion elimination, optimization of programs,
stacks, trees, sorting algorithms, computational 
induction

4.0 4.2 
************************

************************
Document:  CACM-2490.html
************************
************************
Document:  CACM-1529.html
************************
************************
Document:  CACM-2781.html
************************
************************
Document:  CACM-1342.html
************************
************************
Document:  CACM-1367.html
************************
************************
Document:  CACM-2129.html
************************
************************
Document:  CACM-2785.html
************************


glypnir-a programming language for illiac iv

glypnir is one of the earliest existing languages
designed for programming the illiac iv computer. 
the syntax of the language is based on algol 60, but has
been extended to allow the programmer explicitly 
to specify the parallelism of his algorithm in terms of 64-word
vectors.  this paper describes the characteristics, 
goals and philosophy of the language, and discusses some
of the problems associated with parallel computer 
architectures.

cacm march, 1975

lawrie, d. h.
layman, t.
baer, d.
randal, j. m.

glypnir, illiac iv, programming language,
parallel computation, parallel architecture

************************

************************
Document:  CACM-0034.html
************************
************************
Document:  CACM-1269.html
************************
************************
Document:  CACM-1551.html
************************
************************
Document:  CACM-3166.html
************************


computing standard deviations: accuracy

four algorithms for the numerical computation
of the standard deviation 
************************

of the standard deviation of (unweighted) sampled data
are analyzed.  two of the algorithms are well-known in the statistical
and computational literature; the other 
************************
al literature; the other two are new algorithms
specifically intended for automatic computation.  our discussion is 
************************

************************
Document:  CACM-1828.html
************************
************************
Document:  CACM-1536.html
************************


dynamic computation of derivatives

it is shown how wengert's procedure for computation
of derivatives can be implemented conveniently 
by use of compiler-generated complex addition, subtraction,
and linkage to complex arithmetic subroutines.
 evaluation of a function and derivative proceed in
parallel, as in wengert's procedure, 
************************

************************
Document:  CACM-2272.html
************************
************************
Document:  CACM-2725.html
************************
************************
Document:  CACM-2289.html
************************


cellular arrays for the solution of graph problems

a cellular array is a two-dimensional, checkerboard
type interconnection of identical modules 
(or cells), where each cell contains a few bits of
memory and a small amount of combinational logic, 
and communicates mainly with its immediate neighbors
in the array.  the chief computational advantage 
offered by cellular arrays is the improvement in speed
achieved by virtue of the possibilities for parallel 
processing.  in this paper it is shown that cellular
arrays are inherently well suited for the solution 
of many graph problems.  for example, the adjacency
matrix of a graph is easily mapped onto an array; 
each matrix element is stored in one cell of the array,
and typical row and column operations are readily 
implemented by simple cell logic.  a major challenge
in the effective use of cellular arrays for the 
solution of graph problems is the determination of algorithms
that exploit the possibilities for parallelism, 
especially for problems whose solutions 
************************
 for problems whose solutions appear to be inherently
serial.  in particular, several parallelized 
algorithms are presented for the 
************************
 are presented for the solution of certain
spanning tree, distance, and path problems, with 
direct applications to wire routing, pert chart analysis,
and the analysis of many types of networks. 
 these algorithms exhibit a computation time that in
many cases 
************************
 time that in
many cases grows at a rate not exceeding log2 n, 
where n is the number of nodes in the graph.  straightforward
cellular implementations of the well-known 
serial algorithms for these problems require about n
steps, and noncellular implementations require from 
n^2 to n^3 steps.

cacm september, 1972

levitt, k. n.
kautz, w. h.

graph theory, cellular logic-in-memory arrays,
parallel processing, special 
************************

************************
Document:  CACM-1374.html
************************
************************
Document:  CACM-2236.html
************************
************************
Document:  CACM-1924.html
************************
************************
Document:  CACM-0119.html
************************
************************
Document:  CACM-1262.html
************************
************************
Document:  CACM-2830.html
************************
************************
Document:  CACM-1158.html
************************
************************
Document:  CACM-3061.html
************************


simulations of dynamic sequential search algorithms

none

cacm september, 
************************

************************
Document:  CACM-2942.html
************************
************************
Document:  CACM-1569.html
************************
************************
Document:  CACM-0141.html
************************
************************
Document:  CACM-0392.html
************************
************************
Document:  CACM-2714.html
************************
************************
Document:  CACM-3131.html
************************


focus microcomputer number system

focus is a number system and supporting computational
algorithms especially useful for microcomputer 
************************
 useful for microcomputer control and other
signal processing applications.  focus has the wide-ranging
character of floating-point numbers with a uniformity of state distributions
that give focus better than a twofold accuracy advantage
over an equal word length floating-point system.  focus computations
are typically five times faster than single precision fixed-point
or integer arithmetic for a mixture of operations, comparable in
speed with hardware arithmetic for many applications.  algorithms
for 8-bit and 16-bit 
************************

************************
Document:  CACM-2898.html
************************


a conceptual framework for a nonprocedural programming language

a sequential programming language forces the
programmer to prescribe explicitly the order in 
which the operations in his program have to be executed,
even if the order is not relevant to the solution 
of his problem.  the requirement to indicate irrelevant
sequencing can be removed if the language provides 
facilities for specifying a task in a nonprocedural
manner.  in general, a program specified in this 
way will allow concurrent evaluation.  this paper describes
a conceptual framework for a high level programming 
language providing both nonprocedural and sequential
facilities.  within a program, nonprocedural and 
sequential program modules may be nested freely.

cacm december, 1977

kessels, j. l. w.

parallel programming, descriptive 
************************

************************
Document:  CACM-2832.html
************************
************************
Document:  CACM-2819.html
************************
************************
Document:  CACM-2674.html
************************
************************
Document:  CACM-2401.html
************************
